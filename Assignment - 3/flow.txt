6 clusters
3 mappers
4 reducers
(fault tolerance)

1st iteration:
 > 3 partitions before mapping (shards)
 > map 
 > output of each map function->partition into 4 (The partitioning must ensure that all key-value pairs with the same key are sent to the same partition).
 > now we have 12 intermediate files 
 > these files most likely won't have same size.
 > now the reducer will shuffle and sort
 > 



doubts:
Does map function return list of data points and centroids or just for a single point.....
Is each mapper contacting with a reducer? -> Yes
